{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pifs03ExEGh"
      },
      "outputs": [],
      "source": [
        "# import locale\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPl246VNT9eT"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2V--wqRUAci",
        "outputId": "b5e7fd68-b0ac-4a06-8fc7-19318bf8a989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  rubberband-cli\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 87.5 kB of archives.\n",
            "After this operation, 223 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 rubberband-cli amd64 2.0.0-2 [87.5 kB]\n",
            "Fetched 87.5 kB in 0s (255 kB/s)\n",
            "Selecting previously unselected package rubberband-cli.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../rubberband-cli_2.0.0-2_amd64.deb ...\n",
            "Unpacking rubberband-cli (2.0.0-2) ...\n",
            "Setting up rubberband-cli (2.0.0-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pyrubberband\n",
            "  Downloading pyrubberband-0.4.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from pyrubberband) (1.26.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading pyrubberband-0.4.0-py3-none-any.whl (4.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=931fbc43c8aa296dda0ecc0687e5b47988a0e0e0f42d5f741d3b1670e526f17a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: pydub, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pyrubberband, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 pydub-0.25.1 pyrubberband-0.4.0 tiktoken-0.9.0\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.13.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from TTS) (2.5.1+cu124)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.10.2.post1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.6.1)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (7.5.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.67.1)\n",
            "Collecting anyascii>=0.3.0 (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.11.13)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (24.2)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.1.0)\n",
            "Collecting pysbd>=0.3.4 (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.7)\n",
            "Collecting pandas<2.0,>=1.4 (from TTS)\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.10.0)\n",
            "Collecting trainer>=0.0.32 (from TTS)\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul-romanize (from TTS)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from TTS) (3.9.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.48.3)\n",
            "Collecting encodec>=0.1.1 (from TTS)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from TTS)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting num2words (from TTS)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (3.7.5)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.61.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.17.0)\n",
            "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.18.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (1.9.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->TTS) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0,>=1.4->TTS) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->TTS) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->TTS) (1.17.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.15.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.10.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.5.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiDict_core-20250129-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.17.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.5.3)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS) (3.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (4.25.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\n",
            "Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl (937 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
            "Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiDict_core-20250129-py3-none-any.whl (72.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gruut, encodec, bnnumerizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75788 sha256=2704381f5e940cfee9779c3dbcf17cff61e9d5d1600175d47c87cf30c8128ad9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/a0/bc/4dacab52579ab464cffafbe7a8e3792dd36ad9ac288b264843\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=ca09c61e430de8944a8df936e6da628655e1bdc74d3fb47a3957d2efbbe0df65\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=699030dd7a4b02a09a841aa21cf2f4eaee6624ffa55b109f3cc64bf09f70fb72\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/b9/e3/4145416693824818c0b931988a692676ecd4bbf2ea41d1eedd\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=090f386772101960ed1dbfb4606e436fb900b163057f3cc2a49b4f79a73563fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=783e9897f34d029d0b320a0231dd08cd6d3806fac6bb15df31a25ab591181533\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/10/89/a5908dd7a9a032229684b7679396785e19f816667f788087fb\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498313 sha256=9924553a089187f8c544d91f53a4813b2fbf724b71a2ba844e11eb1d65540a37\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/fa/df/5fdf5d3cc26ba859b8698a1f28581d1a6aa081edc6df9847ab\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=3c93b2afd4480ed2123e1e65f627218268b340d2527c3ae061dd71124f2c190a\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/30/52/dc5cd222b4bbde285838fed1f96636e96f85cd75493e79a978\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=34777f2aa4c0d838ec33ff16bb6ebef8e57841e63a7b9b37d4e80c99a426aea4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/eb/59/30b5d15e56347e595f613036cbea0f807ad9621c75cd75d912\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=e7191a4dfa27689f3c964af5c9afe856a3bee47925b8d89386154cec6433d558\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/e7/a0/7c416a3eeaa94ca71bf7bcbc6289cced2263d8ba35e82444bb\n",
            "Successfully built gruut encodec bnnumerizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n",
            "Installing collected packages: sudachipy, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, python-crfsuite, pysbd, pypinyin, num2words, networkx, jsonlines, gruut-ipa, coqpit, anyascii, pandas, g2pkk, dateparser, gruut, trainer, encodec, TTS\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.12.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.19 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 networkx-2.8.8 num2words-0.5.14 pandas-1.5.3 pypinyin-0.53.0 pysbd-0.3.4 python-crfsuite-0.9.11 sudachidict-core-20250129 sudachipy-0.6.10 trainer-0.0.36 unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y rubberband-cli\n",
        "!pip install pyrubberband librosa soundfile pydub openai-whisper openai moviepy\n",
        "!pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4N5jCSbrKYi7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "from openai import OpenAI\n",
        "import librosa\n",
        "import pyrubberband\n",
        "import soundfile as sf\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "from TTS.api import TTS\n",
        "import openai\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSES3mGnKzAa",
        "outputId": "7c422f5b-1b77-47af-dd09-a90de6847542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio extracted successfully!\n"
          ]
        }
      ],
      "source": [
        "# Extracting Audio from Video.\n",
        "\n",
        "def extract_audio(video_path, audio_path):\n",
        "    \"\"\"Extracts audio from a video file using FFmpeg.\"\"\"\n",
        "    if os.path.exists(audio_path):\n",
        "        os.remove(audio_path)\n",
        "    result = subprocess.run(\n",
        "        [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-q:a\", \"0\", \"-map\", \"a\", audio_path],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        check=True\n",
        "    )\n",
        "\n",
        "# Define paths (upload your video to Colab first)\n",
        "video_path = \"/content/self-introduction.mp4\"\n",
        "audio_path = \"/content/self-introduction_audio.wav\"\n",
        "extract_audio(video_path, audio_path)\n",
        "print(\"Audio extracted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNka6a9TLA9R",
        "outputId": "ce3ae496-96e7-418e-f471-5da5cd2008a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original audio duration: 67570 ms\n"
          ]
        }
      ],
      "source": [
        "# Original Audio Duration\n",
        "\n",
        "original_audio = AudioSegment.from_wav(audio_path)\n",
        "total_duration_ms = len(original_audio)\n",
        "print(f\"Original audio duration: {total_duration_ms} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-OU8C7pLFly",
        "outputId": "473275ef-37a6-49b6-9cc9-d451f961f270"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hi, my name is Regente Lentino, you can call me John. I'm 24 years old. I have a three-year work experience with the BPO industry doing inbound and outbound calling. First I served as a technical consultant. We're in my multi-tasking skills has been definitely enhanced. Then eventually I switched to customer service. We're in our integrity place a very big role. Definitely sales must always be on point ahead of the target and at the same time making sure that each and every customer will always be satisfied with my assistance. And on top of all these skills I also have a talent with doing graphic designs, creating flyers, business cards and social media advertisements which will really be helpful for clients marketing needs. And I can assure you that I'm not just gonna be another number on your payroll but definitely a good addition to your company. Once again this is Regente Lentino thank you and goodbye.\n"
          ]
        }
      ],
      "source": [
        "# Transcribe audio using whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "transcript = model.transcribe(\n",
        "    audio=audio_path,\n",
        "    language=\"en\",\n",
        "    word_timestamps=True\n",
        ")\n",
        "print(transcript['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVDntW3iLL8Q",
        "outputId": "ce5bd420-1e30-4af7-9438-8da83ba189a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leading silence detected: 0.85 seconds\n"
          ]
        }
      ],
      "source": [
        "# Detecting starting silence/pauses in video\n",
        "\n",
        "def detect_leading_silence(audio_path, silence_threshold=-40, chunk_size=10):\n",
        "    \"\"\"Detects the duration of silence at the beginning of an audio file.\"\"\"\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "    leading_silence = 0\n",
        "    for i in range(0, len(audio), chunk_size):\n",
        "        chunk = audio[i:i + chunk_size]\n",
        "        if chunk.dBFS > silence_threshold:\n",
        "            break\n",
        "        leading_silence += chunk_size\n",
        "    return leading_silence / 1000.0\n",
        "\n",
        "leading_silence_sec = detect_leading_silence(audio_path)\n",
        "print(f\"Leading silence detected: {leading_silence_sec} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rktTW8iALWMs",
        "outputId": "dd338869-a038-472a-a5c0-013fbb721d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribed sentences with timings:\n",
            " Hi,  my  name  is  Regente  Lentino,  you  can  call  me  John. [0.85 - 5.1899999999999995]\n",
            " I'm  24  years  old. [5.989999999999999 - 7.13]\n",
            " I  have  a  three -year  work  experience  with  the  BPO  industry  doing  inbound  and  outbound  calling. [7.39 - 13.29]\n",
            " First  I  served  as  a  technical  consultant. [14.41 - 17.03]\n",
            " We're  in  my  multi -tasking  skills  has  been  definitely  enhanced. [17.57 - 20.770000000000003]\n",
            " Then  eventually  I  switched  to  customer  service. [21.43 - 24.110000000000003]\n",
            " We're  in  our  integrity  place  a  very  big  role. [24.39 - 27.270000000000003]\n",
            " Definitely  sales  must  always  be  on  point  ahead  of  the  target  and  at  the  same  time  making  sure  that  each  and  every  customer  will  always  be  satisfied  with  my  assistance. [28.41 - 38.870000000000005]\n",
            " And  on  top  of  all  these  skills  I  also  have  a  talent  with  doing  graphic  designs,  creating  flyers,  business  cards  and  social  media  advertisements  which  will  really  be  helpful  for  clients  marketing  needs. [40.13 - 54.050000000000004]\n",
            " And  I  can  assure  you  that  I'm  not  just  gonna  be  another  number  on  your  payroll  but  definitely  a  good  addition  to  your  company. [54.910000000000004 - 61.93]\n",
            " Once  again  this  is  Regente  Lentino  thank  you  and  goodbye. [62.59 - 66.89]\n"
          ]
        }
      ],
      "source": [
        "# Transcription Into sentences\n",
        "\n",
        "sentences = []\n",
        "current_sentence = []\n",
        "sentence_start = None\n",
        "\n",
        "for segment in transcript['segments']:\n",
        "    for word in segment['words']:\n",
        "        adjusted_start = word['start'] + leading_silence_sec\n",
        "        adjusted_end = word['end'] + leading_silence_sec\n",
        "        if not current_sentence:\n",
        "            sentence_start = adjusted_start\n",
        "        current_sentence.append(word['word'])\n",
        "        if word['word'].strip().endswith(('.', '?', '!')):\n",
        "            sentence_end = adjusted_end\n",
        "            sentence_text = ' '.join(current_sentence)\n",
        "            sentences.append({\n",
        "                'text': sentence_text,\n",
        "                'start': sentence_start,\n",
        "                'end': sentence_end\n",
        "            })\n",
        "            current_sentence = []\n",
        "            sentence_start = None\n",
        "if current_sentence:\n",
        "    sentence_end = adjusted_end\n",
        "    sentence_text = ' '.join(current_sentence)\n",
        "    sentences.append({\n",
        "        'text': sentence_text,\n",
        "        'start': sentence_start,\n",
        "        'end': sentence_end\n",
        "    })\n",
        "\n",
        "print(\"Transcribed sentences with timings:\")\n",
        "for sentence in sentences:\n",
        "    print(f\"{sentence['text']} [{sentence['start']} - {sentence['end']}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ekSH8BqgNzz",
        "outputId": "290525de-a4c9-41b6-c518-afe82eb9fa8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': ' Hi,  my  name  is  Regente  Lentino,  you  can  call  me  John.',\n",
              "  'start': 0.85,\n",
              "  'end': 5.1899999999999995},\n",
              " {'text': \" I'm  24  years  old.\", 'start': 5.989999999999999, 'end': 7.13},\n",
              " {'text': ' I  have  a  three -year  work  experience  with  the  BPO  industry  doing  inbound  and  outbound  calling.',\n",
              "  'start': 7.39,\n",
              "  'end': 13.29},\n",
              " {'text': ' First  I  served  as  a  technical  consultant.',\n",
              "  'start': 14.41,\n",
              "  'end': 17.03},\n",
              " {'text': \" We're  in  my  multi -tasking  skills  has  been  definitely  enhanced.\",\n",
              "  'start': 17.57,\n",
              "  'end': 20.770000000000003},\n",
              " {'text': ' Then  eventually  I  switched  to  customer  service.',\n",
              "  'start': 21.43,\n",
              "  'end': 24.110000000000003},\n",
              " {'text': \" We're  in  our  integrity  place  a  very  big  role.\",\n",
              "  'start': 24.39,\n",
              "  'end': 27.270000000000003},\n",
              " {'text': ' Definitely  sales  must  always  be  on  point  ahead  of  the  target  and  at  the  same  time  making  sure  that  each  and  every  customer  will  always  be  satisfied  with  my  assistance.',\n",
              "  'start': 28.41,\n",
              "  'end': 38.870000000000005},\n",
              " {'text': ' And  on  top  of  all  these  skills  I  also  have  a  talent  with  doing  graphic  designs,  creating  flyers,  business  cards  and  social  media  advertisements  which  will  really  be  helpful  for  clients  marketing  needs.',\n",
              "  'start': 40.13,\n",
              "  'end': 54.050000000000004},\n",
              " {'text': \" And  I  can  assure  you  that  I'm  not  just  gonna  be  another  number  on  your  payroll  but  definitely  a  good  addition  to  your  company.\",\n",
              "  'start': 54.910000000000004,\n",
              "  'end': 61.93},\n",
              " {'text': ' Once  again  this  is  Regente  Lentino  thank  you  and  goodbye.',\n",
              "  'start': 62.59,\n",
              "  'end': 66.89}]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5hfpYuft2eh",
        "outputId": "9b3ab747-58ba-4cf4-b8a3-84f499d69aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "नमस्ते, मेरा नाम रेजेंटे लेंटिनो है, आप मुझे जॉन कह सकते हैं। मैं 24 साल का हूँ। मेरे पास BPO इंडस्ट्री में तीन साल का कामयाबी से अनुभव है, इनबाउंड और आउटबाउंड कॉलिंग करते हुए। पहले मैंने एक तकनीकी सलाहकार के रूप में सेवा प्रदान की। हमारे मल्टी-टास्किंग कौशल में निश्चित रूप से सुधार हुआ है। फिर आखिरकार मैंने कस्टमर सर्विस में स्विच किया। हमारे ईमानदारी का बहुत बड़ा योगदान है। निश्चित रूप से बिक्री हमेशा लक्ष्य के आगे होनी चाहिए और उसी समय सुनिश्चित करना चाहिए कि प्रत्येक ग्राहक मेरी सहायता से हमेशा संतुष्ट रहेगा। और इन सभी कौशलों के ऊपर मेरे पास ग्राफिक डिजाइन करने की भी एक प्रतिभा है, फ्लायर्स, बिजनेस कार्ड्स और सोशल मीडिया विज्ञापन बनाने में जो वास्तव में ग्राहकों की विपणन आवश्यकताओं के लिए सहायक होगा। और मैं आपको यह आश्वासन दे सकता हूँ कि मैं आपके पेरोल पर एक और संख्या नहीं होऊंगा, बल्कि निश्चित रूप से आपकी कंपनी में एक अच्छा योगदान होऊंगा। फिर से यह रेजेंटे लेंटिनो है, धन्यवाद और अलविदा।\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from openai import OpenAI\n",
        "\n",
        "openai_api_key = \"YOUR_API_KEY\"\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "def translate_to_hindi(sentences):\n",
        "    \"\"\"Enhanced translation with strict structure constraints.\"\"\"\n",
        "    prompt = \"\"\"Translate these English sentences to Hindi with:\n",
        "1. EXACT same sentence count\n",
        "2. Preserve original punctuation\n",
        "3. Match syllable count where possible\n",
        "4. Use phonetic spellings for technical terms\n",
        "5. Maintain original sentence structure\n",
        "\n",
        "Examples:\n",
        "\"\"\"\n",
        "    for i, sent in enumerate(sentences):\n",
        "        prompt += f\"{i+1}. {sent['text']}\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional translator specializing in audiovisual synchronization.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=2000\n",
        "    )\n",
        "\n",
        "    translated_text = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Extract and clean translations from the numbered output\n",
        "    translations = re.findall(r'^\\s*\\d+\\.\\s*(.*?)(?=\\n\\s*\\d+\\.|$)', translated_text, re.MULTILINE | re.DOTALL)\n",
        "    translations = [clean_translation(text) for text in translations]\n",
        "\n",
        "    if len(translations) != len(sentences):\n",
        "        raise ValueError(f\"Mismatch in translations: expected {len(sentences)}, got {len(translations)}.\\nRaw output:\\n{translated_text}\")\n",
        "\n",
        "    return translations\n",
        "\n",
        "def clean_translation(output_text):\n",
        "    \"\"\" Cleans up translation output by removing unwanted spaces or numbers. \"\"\"\n",
        "    output_text = re.sub(r'\\d+\\.', '', output_text)  # Remove numbering if left over\n",
        "    output_text = re.sub(r'\\s+', ' ', output_text).strip()  # Normalize spaces\n",
        "    return output_text\n",
        "\n",
        "translated_texts = translate_to_hindi(sentences)\n",
        "\n",
        "translated_text = \" \".join(translated_texts).replace(\"'\", \"\").strip()\n",
        "print(translated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "LoHyBpce0VFQ"
      },
      "outputs": [],
      "source": [
        "translated_text = \"नमस्ते, मेरा नाम रेजेंटे लेंटिनो है, आप मुझे जॉन कह सकते हैं। मैं 24 साल का हूँ। मेरे पास BPO इंडस्ट्री में तीन साल का कामयाबी से अनुभव है, इनबाउंड और आउटबाउंड कॉलिंग करते हुए। पहले मैंने एक तकनीकी सलाहकार के रूप में सेवा प्रदान की। हमारे मल्टी-टास्किंग कौशल में निश्चित रूप से सुधार हुआ है। फिर आखिरकार मैंने कस्टमर सर्विस में स्विच किया। हमारे ईमानदारी का बहुत बड़ा योगदान है। निश्चित रूप से बिक्री हमेशा लक्ष्य के आगे होनी चाहिए और उसी समय सुनिश्चित करना चाहिए कि प्रत्येक ग्राहक मेरी सहायता से हमेशा संतुष्ट रहेगा। और इन सभी कौशलों के ऊपर मेरे पास ग्राफिक डिजाइन करने की भी एक प्रतिभा है, फ्लायर्स, बिजनेस कार्ड्स और सोशल मीडिया विज्ञापन बनाने में जो वास्तव में ग्राहकों की विपणन आवश्यकताओं के लिए सहायक होगा। और मैं आपको यह आश्वासन दे सकता हूँ कि मैं आपके पेरोल पर एक और संख्या नहीं होऊंगा, बल्कि निश्चित रूप से आपकी कंपनी में एक अच्छा योगदान होऊंगा। फिर से यह रेजेंटे लेंटिनो है, धन्यवाद और अलविदा।\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY_5poPtL0bS",
        "outputId": "19af9ee1-6f03-461b-a86f-4b63913d919e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hindi sentences with timings:\n",
            "नमस्ते, मेरा नाम रेजेंटे लेंटिनो है, आप मुझे जॉन कह सकते हैं। [0.85 - 5.1899999999999995]\n",
            "मैं 24 साल का हूँ। [5.989999999999999 - 7.13]\n",
            "मेरे पास BPO इंडस्ट्री में तीन साल का कामयाबी से अनुभव है, इनबाउंड और आउटबाउंड कॉलिंग करते हुए। [7.39 - 13.29]\n",
            "पहले मैंने एक तकनीकी सलाहकार के रूप में सेवा प्रदान की। [14.41 - 17.03]\n",
            "हमारे मल्टी-टास्किंग कौशल में निश्चित रूप से सुधार हुआ है। [17.57 - 20.770000000000003]\n",
            "फिर आखिरकार मैंने कस्टमर सर्विस में स्विच किया। [21.43 - 24.110000000000003]\n",
            "हमारे ईमानदारी का बहुत बड़ा योगदान है। [24.39 - 27.270000000000003]\n",
            "निश्चित रूप से बिक्री हमेशा लक्ष्य के आगे होनी चाहिए और उसी समय सुनिश्चित करना चाहिए कि प्रत्येक ग्राहक मेरी सहायता से हमेशा संतुष्ट रहेगा। [28.41 - 38.870000000000005]\n",
            "और इन सभी कौशलों के ऊपर मेरे पास ग्राफिक डिजाइन करने की भी एक प्रतिभा है, फ्लायर्स, बिजनेस कार्ड्स और सोशल मीडिया विज्ञापन बनाने में जो वास्तव में ग्राहकों की विपणन आवश्यकताओं के लिए सहायक होगा। [40.13 - 54.050000000000004]\n",
            "और मैं आपको यह आश्वासन दे सकता हूँ कि मैं आपके पेरोल पर एक और संख्या नहीं होऊंगा, बल्कि निश्चित रूप से आपकी कंपनी में एक अच्छा योगदान होऊंगा। [54.910000000000004 - 61.93]\n",
            "फिर से यह रेजेंटे लेंटिनो है, धन्यवाद और अलविदा। [62.59 - 66.89]\n"
          ]
        }
      ],
      "source": [
        "# Pair hindi sentences with timings\n",
        "\n",
        "def pair_hindi_sentences_with_timings(translated_text, sentences):\n",
        "    \"\"\"Pairs translated Hindi sentences with original timings.\"\"\"\n",
        "    hindi_sentences = [s.strip() for s in translated_text.split('।') if s.strip()]\n",
        "    if len(hindi_sentences) != len(sentences):\n",
        "        raise ValueError(f\"Sentence count mismatch: {len(hindi_sentences)} Hindi vs {len(sentences)} English\")\n",
        "    return [{'text': hindi_sentence + '।', 'start': sentences[i]['start'], 'end': sentences[i]['end']}\n",
        "            for i, hindi_sentence in enumerate(hindi_sentences)]\n",
        "\n",
        "hindi_sentence_timings = pair_hindi_sentences_with_timings(translated_text, sentences)\n",
        "print(\"Hindi sentences with timings:\")\n",
        "for sentence in hindi_sentence_timings:\n",
        "    print(f\"{sentence['text']} [{sentence['start']} - {sentence['end']}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCYi9_vFgixW",
        "outputId": "70ad9efd-5e6e-453a-ac8b-41452ab5ea0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
            "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
            " > Using model: xtts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.speakers = torch.load(speaker_file_path)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Text splitted to sentences.\n",
            "['नमस्ते, मेरा नाम रेजेंटे लेंटिनो है, आप मुझे जॉन कह सकते हैं।']\n",
            " > Processing time: 2.3786957263946533\n",
            " > Real-time factor: 0.3962456240707883\n",
            " > Text splitted to sentences.\n",
            "['मैं चौबीस साल का हूँ।']\n",
            " > Processing time: 3.41571307182312\n",
            " > Real-time factor: 0.40024484117900155\n",
            " > Text splitted to sentences.\n",
            "['मेरे पास BPO इंडस्ट्री में तीन साल का कामयाबी से अनुभव है, इनबाउंड और आउटबाउंड कॉलिंग करते हुए।']\n",
            " > Processing time: 3.0552897453308105\n",
            " > Real-time factor: 0.39274052609682153\n",
            " > Text splitted to sentences.\n",
            "['पहले मैंने एक तकनीकी सलाहकार के रूप में सेवा प्रदान की।']\n",
            " > Processing time: 2.1355342864990234\n",
            " > Real-time factor: 0.38476051622192003\n",
            " > Text splitted to sentences.\n",
            "['हमारे मल्टी-टास्किंग कौशल में निश्चित रूप से सुधार हुआ है।']\n",
            " > Processing time: 2.2374186515808105\n",
            " > Real-time factor: 0.3853821496325215\n",
            " > Text splitted to sentences.\n",
            "['फिर आखिरकार मैंने कस्टमर सर्विस में स्विच किया।']\n",
            " > Processing time: 1.9852280616760254\n",
            " > Real-time factor: 0.38593488820669664\n",
            " > Text splitted to sentences.\n",
            "['हमारे ईमानदारी का बहुत बड़ा योगदान है।']\n",
            " > Processing time: 3.1746268272399902\n",
            " > Real-time factor: 0.3951081546365133\n",
            " > Text splitted to sentences.\n",
            "['निश्चित रूप से बिक्री हमेशा लक्ष्य के आगे होनी चाहिए और उसी समय सुनिश्चित करना चाहिए कि प्रत्येक ग्राहक मेरी सहायता से हमेशा संतुष्ट रहेगा।']\n",
            " > Processing time: 3.9426465034484863\n",
            " > Real-time factor: 0.39808482032126496\n",
            " > Text splitted to sentences.\n",
            "['और इन सभी कौशलों के ऊपर मेरे पास ग्राफिक डिजाइन करने की भी एक प्रतिभा है, फ्लायर्स, बिजनेस कार्ड्स और सोशल मीडिया विज्ञापन बनाने में जो वास्तव में ग्राहकों की विपणन आवश्यकताओं के लिए सहायक होगा।']\n",
            " > Processing time: 5.44559645652771\n",
            " > Real-time factor: 0.4008713539155093\n",
            " > Text splitted to sentences.\n",
            "['और मैं आपको यह आश्वासन दे सकता हूँ कि मैं आपके पेरोल पर एक और संख्या नहीं होऊंगा, बल्कि निश्चित रूप से आपकी कंपनी में एक अच्छा योगदान होऊंगा।']\n",
            " > Processing time: 4.23872447013855\n",
            " > Real-time factor: 0.3959528340276343\n",
            " > Text splitted to sentences.\n",
            "['फिर से यह रेजेंटे लेंटिनो है, धन्यवाद और अलविदा।']\n",
            " > Processing time: 2.143277883529663\n",
            " > Real-time factor: 0.3861556848266854\n",
            "Generated audio files: ['/content/trash/output_0.wav', '/content/trash/output_1.wav', '/content/trash/output_2.wav', '/content/trash/output_3.wav', '/content/trash/output_4.wav', '/content/trash/output_5.wav', '/content/trash/output_6.wav', '/content/trash/output_7.wav', '/content/trash/output_8.wav', '/content/trash/output_9.wav', '/content/trash/output_10.wav']\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Generate TTS Audio\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
        "\n",
        "hindi_numbers = {\n",
        "    \"0\": \"शून्य\", \"1\": \"एक\", \"2\": \"दो\", \"3\": \"तीन\", \"4\": \"चार\", \"5\": \"पांच\", \"6\": \"छह\",\n",
        "    \"7\": \"सात\", \"8\": \"आठ\", \"9\": \"नौ\", \"10\": \"दस\", \"11\": \"ग्यारह\", \"12\": \"बारह\",\n",
        "    \"13\": \"तेरह\", \"14\": \"चौदह\", \"15\": \"पंद्रह\", \"16\": \"सोलह\", \"17\": \"सत्रह\",\n",
        "    \"18\": \"अठारह\", \"19\": \"उन्नीस\", \"20\": \"बीस\", \"21\": \"इक्कीस\", \"22\": \"बाईस\",\n",
        "    \"23\": \"तेईस\", \"24\": \"चौबीस\", \"25\": \"पच्चीस\", \"26\": \"छब्बीस\", \"27\": \"सत्ताईस\",\n",
        "    \"28\": \"अट्ठाईस\", \"29\": \"उनतीस\", \"30\": \"तीस\", \"40\": \"चालीस\", \"50\": \"पचास\",\n",
        "    \"60\": \"साठ\", \"70\": \"सत्तर\", \"80\": \"अस्सी\", \"90\": \"नब्बे\", \"100\": \"सौ\"\n",
        "}\n",
        "\n",
        "def convert_numbers(match):\n",
        "    \"\"\"Converts numbers to Hindi words.\"\"\"\n",
        "    num = match.group()\n",
        "    return hindi_numbers.get(num, num)\n",
        "\n",
        "def preprocess_hindi_text(text):\n",
        "    \"\"\"Preprocesses Hindi text by converting numbers and removing periods.\"\"\"\n",
        "    text = re.sub(r'\\d+', convert_numbers, text)\n",
        "    text = re.sub(r'\\.\\s*', ' ', text)\n",
        "    return text\n",
        "\n",
        "trash_dir = \"/content/trash\"\n",
        "os.makedirs(trash_dir, exist_ok=True)\n",
        "output_files = []\n",
        "for i, timing in enumerate(hindi_sentence_timings):\n",
        "    processed_text = preprocess_hindi_text(timing['text'])\n",
        "    output_path = os.path.join(trash_dir, f\"output_{i}.wav\")\n",
        "    tts.tts_to_file(\n",
        "        text=processed_text,\n",
        "        file_path=output_path,\n",
        "        speaker_wav=\"/content/input_neeraj.m4a\",\n",
        "        language=\"hi\",\n",
        "        speed=0.1\n",
        "    )\n",
        "    output_files.append(output_path)\n",
        "print(\"Generated audio files:\", output_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJP372TkjlkI",
        "outputId": "d15ba904-7a3d-434b-b538-1f566e3edeae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusted audio file paths: ['/content/adjusted_clips/adjusted_clip_0.wav', '/content/adjusted_clips/adjusted_clip_1.wav', '/content/adjusted_clips/adjusted_clip_2.wav', '/content/adjusted_clips/adjusted_clip_3.wav', '/content/adjusted_clips/adjusted_clip_4.wav', '/content/adjusted_clips/adjusted_clip_5.wav', '/content/adjusted_clips/adjusted_clip_6.wav', '/content/adjusted_clips/adjusted_clip_7.wav', '/content/adjusted_clips/adjusted_clip_8.wav', '/content/adjusted_clips/adjusted_clip_9.wav', '/content/adjusted_clips/adjusted_clip_10.wav']\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Adjust Audio Clips for Synchronization\n",
        "def adjust_audio_clips_with_timings(audio_paths, timings, output_folder):\n",
        "    \"\"\"Adjusts each audio clip to match its target duration with speed adjustment and trimming.\"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    adjusted_paths = []\n",
        "    for i, audio_path in enumerate(audio_paths):\n",
        "        audio = AudioSegment.from_wav(audio_path)\n",
        "        current_duration_ms = len(audio)\n",
        "        target_duration_ms = (timings[i]['end'] - timings[i]['start']) * 1000\n",
        "        target_duration_sec = target_duration_ms / 1000.0\n",
        "        speed_factor = current_duration_ms / target_duration_ms\n",
        "        output_path = os.path.join(output_folder, f\"adjusted_clip_{i}.wav\")\n",
        "\n",
        "        atempo_filters = []\n",
        "        remaining_factor = speed_factor\n",
        "        while remaining_factor > 2.0:\n",
        "            atempo_filters.append(\"atempo=2.0\")\n",
        "            remaining_factor /= 2.0\n",
        "        while remaining_factor < 0.5:\n",
        "            atempo_filters.append(\"atempo=0.5\")\n",
        "            remaining_factor /= 0.5\n",
        "        if remaining_factor != 1.0:\n",
        "            atempo_filters.append(f\"atempo={remaining_factor:.4f}\")\n",
        "\n",
        "        atrim_filter = f\"atrim=duration={target_duration_sec}\"\n",
        "        fade_start = max(0, target_duration_sec - 0.01)\n",
        "        afade_filter = f\"afade=t=out:st={fade_start}:d=0.01\"\n",
        "\n",
        "        filter_list = atempo_filters + [atrim_filter, afade_filter]\n",
        "        filter_str = \",\".join(filter_list)\n",
        "\n",
        "        audio.export(output_path, format=\"wav\", parameters=[\"-filter:a\", filter_str])\n",
        "        adjusted_paths.append(output_path)\n",
        "    return adjusted_paths\n",
        "\n",
        "output_folder = \"/content/adjusted_clips\"\n",
        "adjusted_audio_paths = adjust_audio_clips_with_timings(output_files, hindi_sentence_timings, output_folder)\n",
        "print(\"Adjusted audio file paths:\", adjusted_audio_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOmzXWPDjrHZ",
        "outputId": "06ab6ec7-4e75-406b-8fa9-e1e5eb9a3355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synchronized audio saved at: /content/synchronized_output.wav\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Create Synchronized Audio with Offset\n",
        "def create_synchronized_audio(adjusted_audio_paths, timings, total_duration_ms, output_path, start_offset_ms=200):\n",
        "    \"\"\"\n",
        "    Creates synchronized audio by overlaying adjusted clips at adjusted start times.\n",
        "    Applies an offset to all clips except the first one to start earlier.\n",
        "    \"\"\"\n",
        "    synchronized_audio = AudioSegment.silent(duration=total_duration_ms)\n",
        "    for i, audio_path in enumerate(adjusted_audio_paths):\n",
        "        clip = AudioSegment.from_wav(audio_path)\n",
        "        # Apply offset only to clips after the first one (i > 0)\n",
        "        offset = start_offset_ms if i > 0 else 0\n",
        "        start_ms = max(0, int(timings[i]['start'] * 1000) - offset)  # Prevent negative start times\n",
        "        synchronized_audio = synchronized_audio.overlay(clip, position=start_ms)\n",
        "    synchronized_audio.export(output_path, format=\"wav\")\n",
        "    return output_path\n",
        "\n",
        "synchronized_audio_path = \"/content/synchronized_output.wav\"\n",
        "final_audio = create_synchronized_audio(adjusted_audio_paths, hindi_sentence_timings, total_duration_ms, synchronized_audio_path, start_offset_ms=400)\n",
        "print(f\"Synchronized audio saved at: {final_audio}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jWJdg2ijsx0",
        "outputId": "461d6623-07b4-41a0-e0b0-36da8429fdee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7.75M/7.75M [2:06:23<00:00, 59.6MiB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video /content/self-introduction_final.mp4.\n",
            "MoviePy - Writing audio in self-introduction_finalTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "chunk:   0%|          | 0/1490 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:   7%|▋         | 109/1490 [00:00<00:01, 970.26it/s, now=None]\u001b[A\n",
            "chunk:  14%|█▍        | 207/1490 [00:00<00:01, 713.09it/s, now=None]\u001b[A\n",
            "chunk:  19%|█▉        | 282/1490 [00:00<00:02, 560.07it/s, now=None]\u001b[A\n",
            "chunk:  23%|██▎       | 342/1490 [00:00<00:02, 535.70it/s, now=None]\u001b[A\n",
            "chunk:  27%|██▋       | 398/1490 [00:00<00:02, 541.03it/s, now=None]\u001b[A\n",
            "chunk:  30%|███       | 454/1490 [00:00<00:02, 515.08it/s, now=None]\u001b[A\n",
            "chunk:  34%|███▍      | 507/1490 [00:00<00:01, 496.01it/s, now=None]\u001b[A\n",
            "chunk:  37%|███▋      | 557/1490 [00:01<00:02, 455.55it/s, now=None]\u001b[A\n",
            "chunk:  41%|████      | 604/1490 [00:01<00:01, 458.14it/s, now=None]\u001b[A\n",
            "chunk:  45%|████▍     | 668/1490 [00:01<00:01, 492.86it/s, now=None]\u001b[A\n",
            "chunk:  48%|████▊     | 722/1490 [00:01<00:01, 496.82it/s, now=None]\u001b[A\n",
            "chunk:  52%|█████▏    | 776/1490 [00:01<00:01, 508.61it/s, now=None]\u001b[A\n",
            "chunk:  56%|█████▌    | 828/1490 [00:01<00:01, 459.63it/s, now=None]\u001b[A\n",
            "chunk:  59%|█████▉    | 878/1490 [00:01<00:01, 458.54it/s, now=None]\u001b[A\n",
            "chunk:  64%|██████▍   | 953/1490 [00:01<00:01, 535.84it/s, now=None]\u001b[A\n",
            "chunk:  68%|██████▊   | 1008/1490 [00:01<00:00, 487.50it/s, now=None]\u001b[A\n",
            "chunk:  71%|███████   | 1059/1490 [00:02<00:00, 446.86it/s, now=None]\u001b[A\n",
            "chunk:  75%|███████▍  | 1113/1490 [00:02<00:00, 457.82it/s, now=None]\u001b[A\n",
            "chunk:  78%|███████▊  | 1165/1490 [00:02<00:00, 469.29it/s, now=None]\u001b[A\n",
            "chunk:  81%|████████▏ | 1213/1490 [00:02<00:00, 430.70it/s, now=None]\u001b[A\n",
            "chunk:  86%|████████▌ | 1280/1490 [00:02<00:00, 482.42it/s, now=None]\u001b[A\n",
            "chunk:  89%|████████▉ | 1330/1490 [00:02<00:00, 447.95it/s, now=None]\u001b[A\n",
            "chunk:  92%|█████████▏| 1376/1490 [00:02<00:00, 430.90it/s, now=None]\u001b[A\n",
            "chunk:  96%|█████████▌| 1434/1490 [00:02<00:00, 458.61it/s, now=None]\u001b[A\n",
            "chunk:  99%|█████████▉| 1481/1490 [00:03<00:00, 461.54it/s, now=None]\u001b[A\n",
            "100%|██████████| 7.75M/7.75M [2:06:26<00:00, 59.6MiB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/self-introduction_final.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "t:   0%|          | 0/1092 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "t:   7%|▋         | 75/1092 [00:00<00:01, 644.74it/s, now=None]\u001b[A\n",
            "t:  13%|█▎        | 140/1092 [00:00<00:02, 330.78it/s, now=None]\u001b[A\n",
            "t:  17%|█▋        | 181/1092 [00:00<00:03, 294.09it/s, now=None]\u001b[A\n",
            "t:  20%|█▉        | 214/1092 [00:00<00:03, 276.53it/s, now=None]\u001b[A\n",
            "t:  22%|██▏       | 244/1092 [00:00<00:03, 267.01it/s, now=None]\u001b[A\n",
            "t:  25%|██▍       | 272/1092 [00:00<00:03, 258.22it/s, now=None]\u001b[A\n",
            "t:  27%|██▋       | 299/1092 [00:01<00:03, 245.16it/s, now=None]\u001b[A\n",
            "t:  30%|██▉       | 324/1092 [00:01<00:03, 225.16it/s, now=None]\u001b[A\n",
            "t:  32%|███▏      | 349/1092 [00:01<00:03, 229.97it/s, now=None]\u001b[A\n",
            "t:  34%|███▍      | 373/1092 [00:01<00:03, 225.90it/s, now=None]\u001b[A\n",
            "t:  36%|███▋      | 397/1092 [00:01<00:03, 226.53it/s, now=None]\u001b[A\n",
            "t:  38%|███▊      | 420/1092 [00:01<00:02, 226.57it/s, now=None]\u001b[A\n",
            "t:  41%|████      | 443/1092 [00:01<00:02, 226.80it/s, now=None]\u001b[A\n",
            "t:  43%|████▎     | 466/1092 [00:01<00:02, 225.13it/s, now=None]\u001b[A\n",
            "t:  45%|████▍     | 489/1092 [00:01<00:02, 219.28it/s, now=None]\u001b[A\n",
            "t:  47%|████▋     | 513/1092 [00:02<00:02, 222.29it/s, now=None]\u001b[A\n",
            "t:  49%|████▉     | 537/1092 [00:02<00:02, 224.61it/s, now=None]\u001b[A\n",
            "t:  52%|█████▏    | 564/1092 [00:02<00:02, 225.54it/s, now=None]\u001b[A\n",
            "t:  54%|█████▍    | 587/1092 [00:02<00:02, 221.43it/s, now=None]\u001b[A\n",
            "t:  56%|█████▌    | 610/1092 [00:02<00:02, 220.04it/s, now=None]\u001b[A\n",
            "t:  58%|█████▊    | 634/1092 [00:02<00:02, 222.13it/s, now=None]\u001b[A\n",
            "t:  60%|██████    | 660/1092 [00:02<00:01, 220.05it/s, now=None]\u001b[A\n",
            "t:  63%|██████▎   | 686/1092 [00:02<00:01, 229.82it/s, now=None]\u001b[A\n",
            "t:  65%|██████▌   | 713/1092 [00:02<00:01, 240.36it/s, now=None]\u001b[A\n",
            "t:  68%|██████▊   | 738/1092 [00:03<00:01, 242.44it/s, now=None]\u001b[A\n",
            "t:  70%|███████   | 765/1092 [00:03<00:01, 248.09it/s, now=None]\u001b[A\n",
            "t:  73%|███████▎  | 793/1092 [00:03<00:01, 257.09it/s, now=None]\u001b[A\n",
            "t:  75%|███████▌  | 819/1092 [00:03<00:01, 254.34it/s, now=None]\u001b[A\n",
            "t:  78%|███████▊  | 848/1092 [00:03<00:00, 261.90it/s, now=None]\u001b[A\n",
            "t:  80%|████████  | 875/1092 [00:03<00:00, 259.16it/s, now=None]\u001b[A\n",
            "t:  83%|████████▎ | 901/1092 [00:03<00:00, 257.06it/s, now=None]\u001b[A\n",
            "t:  85%|████████▌ | 929/1092 [00:03<00:00, 261.77it/s, now=None]\u001b[A\n",
            "t:  88%|████████▊ | 956/1092 [00:03<00:00, 260.95it/s, now=None]\u001b[A\n",
            "t:  90%|█████████ | 984/1092 [00:03<00:00, 263.90it/s, now=None]\u001b[A\n",
            "t:  93%|█████████▎| 1012/1092 [00:04<00:00, 266.60it/s, now=None]\u001b[A\n",
            "t:  95%|█████████▌| 1039/1092 [00:04<00:00, 266.67it/s, now=None]\u001b[A\n",
            "t:  98%|█████████▊| 1066/1092 [00:04<00:00, 267.41it/s, now=None]\u001b[AWARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/self-introduction.mp4, 691200 bytes wanted but 0 bytes read,at frame 1091/1092, at time 67.55/67.57 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "\n",
            "100%|██████████| 7.75M/7.75M [2:06:30<00:00, 59.6MiB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/self-introduction_final.mp4\n",
            "Final video saved to: /content/self-introduction_final.mp4\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Replace Audio in Video\n",
        "video_clip = VideoFileClip(video_path)\n",
        "new_audio_clip = AudioFileClip(synchronized_audio_path)\n",
        "final_video = video_clip.set_audio(new_audio_clip)\n",
        "final_video_output = \"/content/self-introduction_final.mp4\"\n",
        "final_video.write_videofile(final_video_output, codec=\"libx264\", audio_codec=\"aac\")\n",
        "print(f\"Final video saved to: {final_video_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyjq9x5CssnG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
